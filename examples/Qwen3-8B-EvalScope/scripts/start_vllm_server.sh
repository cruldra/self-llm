#!/bin/bash

# Qwen3-8B vLLM æœåŠ¡å¯åŠ¨è„šæœ¬
# 
# ä½¿ç”¨æ–¹æ³•:
#   bash scripts/start_vllm_server.sh
#   bash scripts/start_vllm_server.sh --model-path /path/to/model
#   bash scripts/start_vllm_server.sh --port 8001

set -e

# é»˜è®¤é…ç½®
MODEL_PATH="./models/Qwen/Qwen3-8B"
HOST="0.0.0.0"
PORT="8000"
SERVED_MODEL_NAME="Qwen3-8B"
MAX_MODEL_LEN="8192"
GPU_MEMORY_UTILIZATION="0.9"

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    case $1 in
        --model-path)
            MODEL_PATH="$2"
            shift 2
            ;;
        --host)
            HOST="$2"
            shift 2
            ;;
        --port)
            PORT="$2"
            shift 2
            ;;
        --served-model-name)
            SERVED_MODEL_NAME="$2"
            shift 2
            ;;
        --max-model-len)
            MAX_MODEL_LEN="$2"
            shift 2
            ;;
        --gpu-memory-utilization)
            GPU_MEMORY_UTILIZATION="$2"
            shift 2
            ;;
        -h|--help)
            echo "ä½¿ç”¨æ–¹æ³•: $0 [é€‰é¡¹]"
            echo ""
            echo "é€‰é¡¹:"
            echo "  --model-path PATH              æ¨¡å‹è·¯å¾„ (é»˜è®¤: ./models/Qwen/Qwen3-8B)"
            echo "  --host HOST                    æœåŠ¡å™¨ä¸»æœº (é»˜è®¤: 0.0.0.0)"
            echo "  --port PORT                    æœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 8000)"
            echo "  --served-model-name NAME       æœåŠ¡æ¨¡å‹åç§° (é»˜è®¤: Qwen3-8B)"
            echo "  --max-model-len LENGTH         æœ€å¤§æ¨¡å‹é•¿åº¦ (é»˜è®¤: 8192)"
            echo "  --gpu-memory-utilization RATIO GPU å†…å­˜åˆ©ç”¨ç‡ (é»˜è®¤: 0.9)"
            echo "  -h, --help                     æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"
            exit 0
            ;;
        *)
            echo "æœªçŸ¥å‚æ•°: $1"
            echo "ä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯"
            exit 1
            ;;
    esac
done

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ‰“å°å‡½æ•°
print_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
check_model() {
    print_info "æ£€æŸ¥æ¨¡å‹è·¯å¾„: $MODEL_PATH"
    
    if [ ! -d "$MODEL_PATH" ]; then
        print_error "æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: $MODEL_PATH"
        print_info "è¯·å…ˆä¸‹è½½æ¨¡å‹: uv run python model_download.py"
        exit 1
    fi
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    required_files=("config.json" "tokenizer.json" "tokenizer_config.json")
    for file in "${required_files[@]}"; do
        if [ ! -f "$MODEL_PATH/$file" ]; then
            print_error "ç¼ºå°‘æ¨¡å‹æ–‡ä»¶: $MODEL_PATH/$file"
            exit 1
        fi
    done
    
    print_success "æ¨¡å‹æ–‡ä»¶æ£€æŸ¥é€šè¿‡"
}

# æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
check_port() {
    print_info "æ£€æŸ¥ç«¯å£ $PORT æ˜¯å¦å¯ç”¨..."
    
    if command -v lsof >/dev/null 2>&1; then
        if lsof -Pi :$PORT -sTCP:LISTEN -t >/dev/null; then
            print_warning "ç«¯å£ $PORT å·²è¢«å ç”¨"
            print_info "å°è¯•æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²è¿è¡Œ..."
            
            # æ£€æŸ¥å¥åº·çŠ¶æ€
            if curl -s "http://localhost:$PORT/health" >/dev/null 2>&1; then
                print_success "vLLM æœåŠ¡å·²åœ¨è¿è¡Œ"
                print_info "API åœ°å€: http://localhost:$PORT/v1"
                exit 0
            else
                print_error "ç«¯å£è¢«å…¶ä»–æœåŠ¡å ç”¨ï¼Œè¯·æ›´æ¢ç«¯å£æˆ–åœæ­¢å ç”¨æœåŠ¡"
                exit 1
            fi
        fi
    else
        print_warning "æ— æ³•æ£€æŸ¥ç«¯å£çŠ¶æ€ (lsof å‘½ä»¤ä¸å¯ç”¨)"
    fi
    
    print_success "ç«¯å£ $PORT å¯ç”¨"
}

# æ£€æŸ¥ GPU
check_gpu() {
    print_info "æ£€æŸ¥ GPU çŠ¶æ€..."
    
    if command -v nvidia-smi >/dev/null 2>&1; then
        gpu_count=$(nvidia-smi --query-gpu=count --format=csv,noheader,nounits | head -1)
        print_info "æ£€æµ‹åˆ° $gpu_count ä¸ª GPU"
        
        # æ˜¾ç¤º GPU ä¿¡æ¯
        nvidia-smi --query-gpu=index,name,memory.total,memory.used,memory.free --format=csv,noheader,nounits | while read line; do
            print_info "GPU: $line"
        done
    else
        print_warning "æœªæ£€æµ‹åˆ° NVIDIA GPU æˆ– nvidia-smi å‘½ä»¤ä¸å¯ç”¨"
        print_warning "å°†ä½¿ç”¨ CPU æ¨¡å¼è¿è¡Œ (æ€§èƒ½è¾ƒä½)"
    fi
}

# å¯åŠ¨ vLLM æœåŠ¡
start_vllm() {
    print_info "å¯åŠ¨ vLLM æœåŠ¡..."
    print_info "æ¨¡å‹è·¯å¾„: $MODEL_PATH"
    print_info "æœåŠ¡åœ°å€: http://$HOST:$PORT"
    print_info "æ¨¡å‹åç§°: $SERVED_MODEL_NAME"
    print_info "æœ€å¤§é•¿åº¦: $MAX_MODEL_LEN"
    print_info "GPU å†…å­˜åˆ©ç”¨ç‡: $GPU_MEMORY_UTILIZATION"
    
    echo "=================================="
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    export VLLM_USE_MODELSCOPE=true
    
    # æ„å»ºå¯åŠ¨å‘½ä»¤
    cmd="vllm serve \"$MODEL_PATH\" \
        --host $HOST \
        --port $PORT \
        --served-model-name \"$SERVED_MODEL_NAME\" \
        --max-model-len $MAX_MODEL_LEN \
        --gpu-memory-utilization $GPU_MEMORY_UTILIZATION \
        --enable-reasoning \
        --reasoning-parser deepseek_r1"
    
    print_info "æ‰§è¡Œå‘½ä»¤: $cmd"
    echo "=================================="
    
    # å¯åŠ¨æœåŠ¡
    eval $cmd
}

# ä¸»å‡½æ•°
main() {
    print_info "ğŸš€ å¯åŠ¨ Qwen3-8B vLLM æœåŠ¡"
    echo "=================================="
    
    # æ£€æŸ¥æ¨¡å‹
    check_model
    
    # æ£€æŸ¥ç«¯å£
    check_port
    
    # æ£€æŸ¥ GPU
    check_gpu
    
    # å¯åŠ¨æœåŠ¡
    start_vllm
}

# ä¿¡å·å¤„ç†
trap 'print_warning "æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢æœåŠ¡..."; exit 130' INT TERM

# è¿è¡Œä¸»å‡½æ•°
main "$@"
