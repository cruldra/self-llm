"""
OpenAI Chat Completions API æµ‹è¯•è„šæœ¬

æµ‹è¯• vLLM å¯åŠ¨çš„ OpenAI å…¼å®¹ API æœåŠ¡å™¨çš„ Chat Completions æ¥å£
"""

import requests
import json
from openai import OpenAI
from typing import List, Dict, Any


def test_with_curl(
    base_url: str = "http://localhost:8000",
    model: str = "Qwen3-8B"
) -> None:
    """
    ä½¿ç”¨ requests åº“æµ‹è¯• Chat Completions API (æ¨¡æ‹Ÿ curl)
    
    Args:
        base_url: API æœåŠ¡å™¨åœ°å€
        model: æ¨¡å‹åç§°
    """
    print("ğŸ”§ ä½¿ç”¨ requests æµ‹è¯• Chat Completions API")
    print("-" * 40)
    
    url = f"{base_url}/v1/chat/completions"
    headers = {
        "Content-Type": "application/json"
    }
    
    # æµ‹è¯•æ•°æ®
    test_cases = [
        {
            "name": "æ•°å­¦æ¨ç†",
            "messages": [
                {"role": "user", "content": "æˆ‘æƒ³é—®ä½ ï¼Œ5çš„é˜¶ä¹˜æ˜¯å¤šå°‘ï¼Ÿ<think>\n"}
            ],
            "temperature": 0.6
        },
        {
            "name": "ç®€å•å¯¹è¯",
            "messages": [
                {"role": "user", "content": "ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ"}
            ],
            "temperature": 0.7
        },
        {
            "name": "å¤šè½®å¯¹è¯",
            "messages": [
                {"role": "user", "content": "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ"},
                {"role": "assistant", "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ..."},
                {"role": "user", "content": "å®ƒæœ‰ä»€ä¹ˆåº”ç”¨ï¼Ÿ"}
            ],
            "temperature": 0.8
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['name']}")
        
        data = {
            "model": model,
            "messages": test_case["messages"],
            "temperature": test_case["temperature"],
            "max_tokens": 1024
        }
        
        try:
            response = requests.post(url, headers=headers, json=data, timeout=60)
            response.raise_for_status()
            
            result = response.json()
            
            print(f"âœ… è¯·æ±‚æˆåŠŸ")
            print(f"ğŸ“Š çŠ¶æ€ç : {response.status_code}")
            print(f"ğŸ†” è¯·æ±‚ID: {result.get('id', 'N/A')}")
            
            # æ˜¾ç¤ºå›å¤å†…å®¹
            choice = result['choices'][0]
            message = choice['message']
            
            print(f"ğŸ“ å›å¤å†…å®¹: {message['content'][:200]}...")
            
            # å¦‚æœæœ‰æ¨ç†å†…å®¹ï¼Œä¹Ÿæ˜¾ç¤º
            if 'reasoning_content' in message and message['reasoning_content']:
                print(f"ğŸ’­ æ¨ç†è¿‡ç¨‹: {message['reasoning_content'][:100]}...")
            
            print(f"ğŸ“ˆ Token ä½¿ç”¨: {result.get('usage', {})}")
            print(f"ğŸ ç»“æŸåŸå› : {choice.get('finish_reason', 'N/A')}")
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±è´¥: {e}")
        except Exception as e:
            print(f"âŒ å…¶ä»–é”™è¯¯: {e}")


def test_with_openai_client(
    base_url: str = "http://localhost:8000/v1",
    api_key: str = "sk-xxx",
    model: str = "Qwen3-8B"
) -> None:
    """
    ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯æµ‹è¯• Chat Completions API
    
    Args:
        base_url: API æœåŠ¡å™¨åœ°å€
        api_key: API å¯†é’¥ (éšä¾¿å¡«å†™)
        model: æ¨¡å‹åç§°
    """
    print("\nğŸ”§ ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯æµ‹è¯• Chat Completions API")
    print("-" * 40)
    
    client = OpenAI(
        base_url=base_url,
        api_key=api_key
    )
    
    # æµ‹è¯•æ•°æ®
    test_cases = [
        {
            "name": "æŠ€æœ¯é—®ç­”",
            "messages": [
                {"role": "user", "content": "ä»€ä¹ˆæ˜¯ Transformer æ¶æ„ï¼Ÿ"}
            ],
            "temperature": 0.3
        },
        {
            "name": "ä»£ç ç”Ÿæˆ",
            "messages": [
                {"role": "user", "content": "å†™ä¸€ä¸ª Python å‡½æ•°æ¥å®ç°å¿«é€Ÿæ’åºç®—æ³•"}
            ],
            "temperature": 0.2
        },
        {
            "name": "åˆ›æ„å†™ä½œ",
            "messages": [
                {"role": "user", "content": "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—"}
            ],
            "temperature": 0.9
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['name']}")
        
        try:
            chat_completion = client.chat.completions.create(
                model=model,
                messages=test_case["messages"],
                temperature=test_case["temperature"],
                max_tokens=1024
            )
            
            print(f"âœ… è¯·æ±‚æˆåŠŸ")
            print(f"ğŸ†” è¯·æ±‚ID: {chat_completion.id}")
            
            # æ˜¾ç¤ºå›å¤å†…å®¹
            message = chat_completion.choices[0].message
            print(f"ğŸ“ å›å¤å†…å®¹: {message.content[:200]}...")
            
            # å¦‚æœæœ‰æ¨ç†å†…å®¹ï¼Œä¹Ÿæ˜¾ç¤º
            if hasattr(message, 'reasoning_content') and message.reasoning_content:
                print(f"ğŸ’­ æ¨ç†è¿‡ç¨‹: {message.reasoning_content[:100]}...")
            
            print(f"ğŸ“ˆ Token ä½¿ç”¨: {chat_completion.usage}")
            print(f"ğŸ ç»“æŸåŸå› : {chat_completion.choices[0].finish_reason}")
            
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")


def test_streaming_chat(
    base_url: str = "http://localhost:8000/v1",
    api_key: str = "sk-xxx",
    model: str = "Qwen3-8B"
) -> None:
    """
    æµ‹è¯•æµå¼ Chat Completions API
    
    Args:
        base_url: API æœåŠ¡å™¨åœ°å€
        api_key: API å¯†é’¥
        model: æ¨¡å‹åç§°
    """
    print("\nğŸ”§ æµ‹è¯•æµå¼ Chat Completions API")
    print("-" * 40)
    
    client = OpenAI(
        base_url=base_url,
        api_key=api_key
    )
    
    messages = [
        {"role": "user", "content": "è¯·è¯¦ç»†è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼ŒåŒ…æ‹¬å…¶ä¸»è¦ç±»å‹å’Œåº”ç”¨ã€‚"}
    ]
    
    print("ğŸ“ é—®é¢˜: è¯·è¯¦ç»†è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼ŒåŒ…æ‹¬å…¶ä¸»è¦ç±»å‹å’Œåº”ç”¨ã€‚")
    print("ğŸ’¬ æµå¼å›å¤:")
    
    try:
        stream = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.7,
            max_tokens=1024,
            stream=True
        )
        
        full_response = ""
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                full_response += content
        
        print(f"\n\nâœ… æµå¼å“åº”å®Œæˆ")
        print(f"ğŸ“ æ€»é•¿åº¦: {len(full_response)} å­—ç¬¦")
        
    except Exception as e:
        print(f"âŒ æµå¼è¯·æ±‚å¤±è´¥: {e}")


def interactive_chat(
    base_url: str = "http://localhost:8000/v1",
    api_key: str = "sk-xxx",
    model: str = "Qwen3-8B"
) -> None:
    """
    äº¤äº’å¼èŠå¤©æµ‹è¯•
    
    Args:
        base_url: API æœåŠ¡å™¨åœ°å€
        api_key: API å¯†é’¥
        model: æ¨¡å‹åç§°
    """
    print("\nğŸ’¬ äº¤äº’å¼èŠå¤©æµ‹è¯• (è¾“å…¥ 'quit' é€€å‡º)")
    print("-" * 40)
    
    client = OpenAI(
        base_url=base_url,
        api_key=api_key
    )
    
    messages = []
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ç”¨æˆ·: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            if not user_input:
                continue
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": user_input})
            
            # è·å–åŠ©æ‰‹å›å¤
            chat_completion = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.7,
                max_tokens=1024
            )
            
            assistant_message = chat_completion.choices[0].message.content
            print(f"\nğŸ¤– åŠ©æ‰‹: {assistant_message}")
            
            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
            messages.append({"role": "assistant", "content": assistant_message})
            
            # é™åˆ¶å†å²é•¿åº¦
            if len(messages) > 10:
                messages = messages[-10:]
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å¯¹è¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª OpenAI Chat Completions API æµ‹è¯•")
    print("=" * 50)
    
    base_url = "http://localhost:8000"
    model = "Qwen3-8B"
    
    # æ£€æŸ¥æœåŠ¡å™¨å¥åº·çŠ¶æ€
    try:
        response = requests.get(f"{base_url}/v1/models", timeout=5)
        if response.status_code != 200:
            print("âŒ æœåŠ¡å™¨æœªæ­£å¸¸è¿è¡Œ")
            print("ğŸ’¡ è¯·å…ˆå¯åŠ¨æœåŠ¡å™¨:")
            print("   uv run python start_api_server.py")
            return
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
        print("ğŸ’¡ è¯·å…ˆå¯åŠ¨æœåŠ¡å™¨:")
        print("   uv run python start_api_server.py")
        return
    
    print("âœ… æœåŠ¡å™¨è¿è¡Œæ­£å¸¸")
    
    # ä½¿ç”¨ requests æµ‹è¯•
    test_with_curl(base_url, model)
    
    # ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯æµ‹è¯•
    test_with_openai_client(f"{base_url}/v1", "sk-xxx", model)
    
    # æµ‹è¯•æµå¼å“åº”
    test_streaming_chat(f"{base_url}/v1", "sk-xxx", model)
    
    print("\n" + "=" * 50)
    print("ğŸ‰ Chat Completions API æµ‹è¯•å®Œæˆï¼")
    
    # è¯¢é—®æ˜¯å¦è¿›å…¥äº¤äº’æ¨¡å¼
    try:
        choice = input("\nâ“ æ˜¯å¦è¿›å…¥äº¤äº’å¼èŠå¤©æ¨¡å¼ï¼Ÿ(y/n): ").strip().lower()
        if choice in ['y', 'yes', 'æ˜¯']:
            interactive_chat(f"{base_url}/v1", "sk-xxx", model)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ å†è§ï¼")


if __name__ == "__main__":
    main()
